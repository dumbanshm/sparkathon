{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Waste Reduction System: Dead Stock Prediction & Recommendation Engine\n",
        "\n",
        "This notebook implements a system to:\n",
        "1. Predict dead stock (products likely to expire before being sold)\n",
        "2. Recommend soon-to-expire items to appropriate users to minimize wastage\n",
        "\n",
        "## Phase 1: Data Foundation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "### Step 1.1: Import Required Libraries\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mRunning cells with 'Python 3.10.9' requires the ipykernel package.\n",
            "\u001b[1;31m<a href='command:jupyter.createPythonEnvAndSelectController'>Create a Python Environment</a> with the required packages."
          ]
        }
      ],
      "source": [
        "# Data manipulation and analysis\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "# Visualization\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Machine Learning\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
        "from sklearn.metrics import classification_report, confusion_matrix, mean_squared_error\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# Warnings\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set display options\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.width', None)\n",
        "\n",
        "print(\"Libraries imported successfully!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "### Step 1.2: Load the Datasets\n",
        "\n",
        "We'll load the three datasets generated by the walmart_new.py script:\n",
        "- **fake_users.csv**: Customer profiles with dietary preferences, allergies, and shopping habits\n",
        "- **fake_products.csv**: Product inventory with expiry dates, prices, and nutritional info\n",
        "- **fake_transactions.csv**: Historical purchase data linking users and products\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load the datasets\n",
        "users_df = pd.read_csv('../datasets/fake_users.csv')\n",
        "products_df = pd.read_csv('../datasets/fake_products.csv')\n",
        "transactions_df = pd.read_csv('../datasets/fake_transactions.csv')\n",
        "\n",
        "print(\"Dataset shapes:\")\n",
        "print(f\"Users: {users_df.shape}\")\n",
        "print(f\"Products: {products_df.shape}\")\n",
        "print(f\"Transactions: {transactions_df.shape}\")\n",
        "\n",
        "# Convert date columns to datetime\n",
        "date_columns = {\n",
        "    'users_df': ['last_purchase_date'],\n",
        "    'products_df': ['packaging_date', 'expiry_date'],\n",
        "    'transactions_df': ['purchase_date']\n",
        "}\n",
        "\n",
        "for df_name, cols in date_columns.items():\n",
        "    df = eval(df_name)\n",
        "    for col in cols:\n",
        "        if col in df.columns:\n",
        "            df[col] = pd.to_datetime(df[col])\n",
        "\n",
        "print(\"\\nDate columns converted successfully!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "### Step 1.3: Data Exploration and Understanding\n",
        "\n",
        "Let's explore each dataset to understand the data structure and identify key features for our models.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Explore Users Dataset\n",
        "print(\"USERS DATASET OVERVIEW:\")\n",
        "print(\"=\"*50)\n",
        "print(users_df.head())\n",
        "print(\"\\nColumn Info:\")\n",
        "print(users_df.info())\n",
        "print(\"\\nDiet Type Distribution:\")\n",
        "print(users_df['diet_type'].value_counts())\n",
        "print(\"\\nDiscount Preference Distribution:\")\n",
        "print(users_df['prefers_discount'].value_counts())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Explore Products Dataset\n",
        "print(\"\\nPRODUCTS DATASET OVERVIEW:\")\n",
        "print(\"=\"*50)\n",
        "print(products_df.head())\n",
        "print(\"\\nColumn Info:\")\n",
        "print(products_df.info())\n",
        "print(\"\\nCategory Distribution:\")\n",
        "print(products_df['category'].value_counts())\n",
        "print(\"\\nCurrent Discount Distribution:\")\n",
        "print(products_df['current_discount_percent'].value_counts())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Explore Transactions Dataset\n",
        "print(\"\\nTRANSACTIONS DATASET OVERVIEW:\")\n",
        "print(\"=\"*50)\n",
        "print(transactions_df.head())\n",
        "print(\"\\nColumn Info:\")\n",
        "print(transactions_df.info())\n",
        "print(\"\\nTransaction Statistics:\")\n",
        "print(transactions_df.describe())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## Phase 2: Dead Stock Prediction\n",
        "\n",
        "### Step 2.1: Feature Engineering for Dead Stock Prediction\n",
        "\n",
        "To predict dead stock, we need to engineer features that capture:\n",
        "1. **Product shelf life characteristics** - How long until expiry?\n",
        "2. **Sales velocity** - How fast is the product selling?\n",
        "3. **Inventory turnover** - What percentage of stock moves in a given time?\n",
        "4. **Product characteristics** - Category, price, discount patterns\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calculate current date for reference\n",
        "current_date = pd.Timestamp.now()\n",
        "\n",
        "# Add days until expiry for each product\n",
        "products_df['days_until_expiry'] = (products_df['expiry_date'] - current_date).dt.days\n",
        "products_df['total_shelf_life'] = (products_df['expiry_date'] - products_df['packaging_date']).dt.days\n",
        "products_df['shelf_life_remaining_pct'] = products_df['days_until_expiry'] / products_df['total_shelf_life'] * 100\n",
        "\n",
        "# Calculate sales metrics for each product\n",
        "sales_metrics = transactions_df.groupby('product_id').agg({\n",
        "    'quantity': ['sum', 'mean', 'count'],\n",
        "    'purchase_date': ['min', 'max'],\n",
        "    'discount_percent': 'mean',\n",
        "    'user_engaged_with_deal': 'mean'\n",
        "}).reset_index()\n",
        "\n",
        "# Flatten column names\n",
        "sales_metrics.columns = ['product_id', 'total_quantity_sold', 'avg_quantity_per_sale', \n",
        "                        'number_of_sales', 'first_sale_date', 'last_sale_date',\n",
        "                        'avg_discount_given', 'avg_user_engagement']\n",
        "\n",
        "# Calculate days since last sale\n",
        "sales_metrics['days_since_last_sale'] = (current_date - sales_metrics['last_sale_date']).dt.days\n",
        "\n",
        "# Calculate sales velocity (units sold per day)\n",
        "sales_metrics['days_on_market'] = (sales_metrics['last_sale_date'] - sales_metrics['first_sale_date']).dt.days + 1\n",
        "sales_metrics['sales_velocity'] = sales_metrics['total_quantity_sold'] / sales_metrics['days_on_market']\n",
        "\n",
        "# Merge sales metrics with products\n",
        "products_enhanced = products_df.merge(sales_metrics, on='product_id', how='left')\n",
        "\n",
        "# Fill NaN values for products with no sales\n",
        "products_enhanced['total_quantity_sold'].fillna(0, inplace=True)\n",
        "products_enhanced['number_of_sales'].fillna(0, inplace=True)\n",
        "products_enhanced['sales_velocity'].fillna(0, inplace=True)\n",
        "products_enhanced['days_since_last_sale'].fillna(999, inplace=True)  # Large number for never sold\n",
        "\n",
        "print(\"Enhanced Product Features:\")\n",
        "print(products_enhanced[['product_id', 'name', 'days_until_expiry', 'total_quantity_sold', \n",
        "                        'sales_velocity', 'days_since_last_sale']].head(10))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "### Step 2.2: Define Dead Stock\n",
        "\n",
        "We'll define a product as \"dead stock\" if:\n",
        "1. It has less than 30 days until expiry AND\n",
        "2. Its sales velocity suggests it won't sell out before expiry\n",
        "\n",
        "This is a practical definition that helps us identify products at risk of wastage.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define dead stock based on our criteria\n",
        "def calculate_dead_stock_risk(row):\n",
        "    \"\"\"\n",
        "    Calculate if a product is at risk of becoming dead stock.\n",
        "    Returns: 1 if dead stock risk, 0 otherwise\n",
        "    \"\"\"\n",
        "    # If already expired\n",
        "    if row['days_until_expiry'] <= 0:\n",
        "        return 1\n",
        "    \n",
        "    # If no sales history and less than 30 days to expiry\n",
        "    if row['sales_velocity'] == 0 and row['days_until_expiry'] < 30:\n",
        "        return 1\n",
        "    \n",
        "    # If sales velocity suggests won't sell out before expiry\n",
        "    # Assuming we need to sell at least 80% of typical inventory\n",
        "    if row['sales_velocity'] > 0:\n",
        "        projected_sales = row['sales_velocity'] * row['days_until_expiry']\n",
        "        # Assuming average inventory of 100 units per product\n",
        "        if projected_sales < 80 and row['days_until_expiry'] < 30:\n",
        "            return 1\n",
        "    \n",
        "    return 0\n",
        "\n",
        "# Apply the function to create labels\n",
        "products_enhanced['is_dead_stock_risk'] = products_enhanced.apply(calculate_dead_stock_risk, axis=1)\n",
        "\n",
        "# Create additional risk score (continuous variable)\n",
        "products_enhanced['dead_stock_risk_score'] = (\n",
        "    (30 - products_enhanced['days_until_expiry'].clip(lower=0, upper=30)) / 30 * 0.5 +  # Expiry urgency\n",
        "    (1 - products_enhanced['sales_velocity'].clip(upper=5) / 5) * 0.3 +  # Low sales velocity\n",
        "    (products_enhanced['days_since_last_sale'].clip(upper=30) / 30) * 0.2  # Stagnation\n",
        ")\n",
        "\n",
        "print(f\"Dead Stock Risk Distribution:\")\n",
        "print(products_enhanced['is_dead_stock_risk'].value_counts())\n",
        "print(f\"\\nPercentage of products at risk: {products_enhanced['is_dead_stock_risk'].mean() * 100:.1f}%\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "### Step 2.3: Build Dead Stock Prediction Model\n",
        "\n",
        "We'll use a Random Forest Classifier to predict dead stock risk based on product features. This model will help us proactively identify products that need intervention.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Prepare features for the model\n",
        "feature_columns = [\n",
        "    'days_until_expiry', 'total_shelf_life', 'shelf_life_remaining_pct',\n",
        "    'total_quantity_sold', 'avg_quantity_per_sale', 'number_of_sales',\n",
        "    'days_since_last_sale', 'sales_velocity', 'price_mrp', \n",
        "    'current_discount_percent', 'weight_grams'\n",
        "]\n",
        "\n",
        "# One-hot encode categorical variables\n",
        "categorical_features = ['category', 'diet_type']\n",
        "products_encoded = pd.get_dummies(products_enhanced, columns=categorical_features, prefix=categorical_features)\n",
        "\n",
        "# Update feature columns to include encoded features\n",
        "encoded_columns = [col for col in products_encoded.columns if any(cat in col for cat in categorical_features)]\n",
        "feature_columns.extend(encoded_columns)\n",
        "\n",
        "# Prepare X and y\n",
        "X = products_encoded[feature_columns].fillna(0)\n",
        "y = products_encoded['is_dead_stock_risk']\n",
        "\n",
        "# Split the data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "# Scale the features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "print(f\"Training set shape: {X_train.shape}\")\n",
        "print(f\"Test set shape: {X_test.shape}\")\n",
        "print(f\"Class distribution in training set:\")\n",
        "print(y_train.value_counts(normalize=True))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train the Random Forest model\n",
        "rf_model = RandomForestClassifier(\n",
        "    n_estimators=100,\n",
        "    max_depth=10,\n",
        "    min_samples_split=5,\n",
        "    min_samples_leaf=2,\n",
        "    random_state=42,\n",
        "    class_weight='balanced'  # Handle class imbalance\n",
        ")\n",
        "\n",
        "rf_model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = rf_model.predict(X_test_scaled)\n",
        "y_pred_proba = rf_model.predict_proba(X_test_scaled)[:, 1]\n",
        "\n",
        "# Evaluate the model\n",
        "print(\"Model Performance:\")\n",
        "print(\"=\"*50)\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# Feature importance\n",
        "feature_importance = pd.DataFrame({\n",
        "    'feature': X.columns,\n",
        "    'importance': rf_model.feature_importances_\n",
        "}).sort_values('importance', ascending=False).head(10)\n",
        "\n",
        "print(\"\\nTop 10 Most Important Features:\")\n",
        "print(feature_importance)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## Phase 3: Recommendation System\n",
        "\n",
        "### Step 3.1: Build User-Product Compatibility Matrix\n",
        "\n",
        "The recommendation system will match users to products based on:\n",
        "1. **Dietary compatibility** - Matching user dietary restrictions with product attributes\n",
        "2. **Allergy safety** - Ensuring products don't contain user allergens\n",
        "3. **Price sensitivity** - Matching discount preferences\n",
        "4. **Category preferences** - Recommending from preferred categories\n",
        "5. **Urgency** - Prioritizing products closer to expiry\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create recommendation system functions\n",
        "def is_diet_compatible(user_diet, product_diet):\n",
        "    \"\"\"Check if product diet type is compatible with user's diet\"\"\"\n",
        "    diet_hierarchy = {\n",
        "        \"non-vegetarian\": 3,\n",
        "        \"eggs\": 2,\n",
        "        \"vegetarian\": 1,\n",
        "        \"vegan\": 0\n",
        "    }\n",
        "    return diet_hierarchy.get(product_diet, 0) <= diet_hierarchy.get(user_diet, 3)\n",
        "\n",
        "def is_allergen_safe(user_allergies, product_allergens):\n",
        "    \"\"\"Check if product is safe for user's allergies\"\"\"\n",
        "    if isinstance(user_allergies, str):\n",
        "        user_allergies = eval(user_allergies) if user_allergies != '[]' else []\n",
        "    if isinstance(product_allergens, str):\n",
        "        product_allergens = eval(product_allergens) if product_allergens != '[]' else []\n",
        "    \n",
        "    return not any(allergen in product_allergens for allergen in user_allergies)\n",
        "\n",
        "def calculate_user_product_score(user, product, urgency_weight=0.3):\n",
        "    \"\"\"\n",
        "    Calculate compatibility score between user and product\n",
        "    Higher score = better match\n",
        "    \"\"\"\n",
        "    score = 0\n",
        "    \n",
        "    # Diet compatibility (mandatory)\n",
        "    if not is_diet_compatible(user['diet_type'], product['diet_type']):\n",
        "        return 0\n",
        "    \n",
        "    # Allergen safety (mandatory)\n",
        "    if not is_allergen_safe(user['allergies'], product['allergens']):\n",
        "        return 0\n",
        "    \n",
        "    # Category preference (0-30 points)\n",
        "    if isinstance(user['preferred_categories'], str):\n",
        "        preferred_cats = eval(user['preferred_categories'])\n",
        "    else:\n",
        "        preferred_cats = user['preferred_categories']\n",
        "    \n",
        "    if product['category'] in preferred_cats:\n",
        "        score += 30\n",
        "    \n",
        "    # Discount preference (0-20 points)\n",
        "    if user['prefers_discount'] and product['current_discount_percent'] > 0:\n",
        "        score += min(20, product['current_discount_percent'] / 2)\n",
        "    elif not user['prefers_discount'] and product['current_discount_percent'] == 0:\n",
        "        score += 10\n",
        "    \n",
        "    # Price range compatibility (0-20 points)\n",
        "    # Assuming users prefer products in moderate price range\n",
        "    if 50 <= product['price_mrp'] <= 200:\n",
        "        score += 20\n",
        "    elif 200 < product['price_mrp'] <= 350:\n",
        "        score += 10\n",
        "    \n",
        "    # Urgency score for expiring products (0-30 points)\n",
        "    if product['days_until_expiry'] <= 7:\n",
        "        urgency_score = 30\n",
        "    elif product['days_until_expiry'] <= 14:\n",
        "        urgency_score = 20\n",
        "    elif product['days_until_expiry'] <= 30:\n",
        "        urgency_score = 10\n",
        "    else:\n",
        "        urgency_score = 0\n",
        "    \n",
        "    score += urgency_score * urgency_weight\n",
        "    \n",
        "    # Dead stock risk bonus (0-20 points)\n",
        "    if product.get('is_dead_stock_risk', 0) == 1:\n",
        "        score += 20\n",
        "    \n",
        "    return score\n",
        "\n",
        "print(\"Recommendation system functions created successfully!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "### Step 3.2: Generate Recommendations\n",
        "\n",
        "Now let's create a function that generates personalized recommendations for each user, prioritizing products at risk of becoming dead stock.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_user_recommendations(user_id, products_df, users_df, top_n=5, focus_on_expiring=True):\n",
        "    \"\"\"\n",
        "    Get top N product recommendations for a specific user\n",
        "    \"\"\"\n",
        "    # Get user data\n",
        "    user = users_df[users_df['user_id'] == user_id].iloc[0]\n",
        "    \n",
        "    # Filter products that are still available (not expired)\n",
        "    available_products = products_df[products_df['days_until_expiry'] > 0].copy()\n",
        "    \n",
        "    # If focusing on expiring products, filter to those expiring soon\n",
        "    if focus_on_expiring:\n",
        "        available_products = available_products[\n",
        "            (available_products['days_until_expiry'] <= 30) | \n",
        "            (available_products['is_dead_stock_risk'] == 1)\n",
        "        ]\n",
        "    \n",
        "    # Calculate scores for all available products\n",
        "    scores = []\n",
        "    for _, product in available_products.iterrows():\n",
        "        score = calculate_user_product_score(user, product)\n",
        "        if score > 0:  # Only include compatible products\n",
        "            scores.append({\n",
        "                'product_id': product['product_id'],\n",
        "                'product_name': product['name'],\n",
        "                'category': product['category'],\n",
        "                'days_until_expiry': product['days_until_expiry'],\n",
        "                'current_discount': product['current_discount_percent'],\n",
        "                'price': product['price_mrp'],\n",
        "                'compatibility_score': score,\n",
        "                'is_dead_stock_risk': product['is_dead_stock_risk']\n",
        "            })\n",
        "    \n",
        "    # Sort by score and return top N\n",
        "    recommendations = sorted(scores, key=lambda x: x['compatibility_score'], reverse=True)[:top_n]\n",
        "    \n",
        "    return pd.DataFrame(recommendations)\n",
        "\n",
        "# Test the recommendation system with a sample user\n",
        "sample_user_id = users_df['user_id'].iloc[0]\n",
        "recommendations = get_user_recommendations(sample_user_id, products_enhanced, users_df)\n",
        "\n",
        "print(f\"Recommendations for User {sample_user_id}:\")\n",
        "print(\"=\"*80)\n",
        "print(f\"User Profile:\")\n",
        "user_info = users_df[users_df['user_id'] == sample_user_id].iloc[0]\n",
        "print(f\"- Diet Type: {user_info['diet_type']}\")\n",
        "print(f\"- Allergies: {user_info['allergies']}\")\n",
        "print(f\"- Prefers Discount: {user_info['prefers_discount']}\")\n",
        "print(f\"- Preferred Categories: {user_info['preferred_categories']}\")\n",
        "print(\"\\nRecommended Products:\")\n",
        "print(recommendations)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## Phase 4: Integrated Waste Reduction System\n",
        "\n",
        "### Step 4.1: Create the Complete System\n",
        "\n",
        "Now we'll integrate both components into a comprehensive waste reduction system that:\n",
        "1. Identifies products at risk of becoming dead stock\n",
        "2. Matches these products with the most suitable users\n",
        "3. Generates targeted recommendations to minimize waste\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class WasteReductionSystem:\n",
        "    \"\"\"\n",
        "    Integrated system for predicting dead stock and recommending products to minimize waste\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self, users_df, products_df, transactions_df, model=None, scaler=None):\n",
        "        self.users_df = users_df\n",
        "        self.products_df = products_df\n",
        "        self.transactions_df = transactions_df\n",
        "        self.model = model\n",
        "        self.scaler = scaler\n",
        "        self.products_enhanced = None\n",
        "        \n",
        "    def enhance_product_features(self):\n",
        "        \"\"\"Add calculated features to products dataframe\"\"\"\n",
        "        current_date = pd.Timestamp.now()\n",
        "        \n",
        "        # Copy products_df to avoid modifying original\n",
        "        self.products_enhanced = self.products_df.copy()\n",
        "        \n",
        "        # Add time-based features\n",
        "        self.products_enhanced['days_until_expiry'] = (\n",
        "            self.products_enhanced['expiry_date'] - current_date\n",
        "        ).dt.days\n",
        "        \n",
        "        # Calculate sales metrics\n",
        "        sales_metrics = self.transactions_df.groupby('product_id').agg({\n",
        "            'quantity': ['sum', 'mean', 'count'],\n",
        "            'purchase_date': ['min', 'max'],\n",
        "            'discount_percent': 'mean'\n",
        "        }).reset_index()\n",
        "        \n",
        "        sales_metrics.columns = ['product_id', 'total_quantity_sold', 'avg_quantity_per_sale',\n",
        "                                'number_of_sales', 'first_sale_date', 'last_sale_date',\n",
        "                                'avg_discount_given']\n",
        "        \n",
        "        # Calculate sales velocity\n",
        "        sales_metrics['days_since_last_sale'] = (\n",
        "            current_date - sales_metrics['last_sale_date']\n",
        "        ).dt.days\n",
        "        sales_metrics['days_on_market'] = (\n",
        "            sales_metrics['last_sale_date'] - sales_metrics['first_sale_date']\n",
        "        ).dt.days + 1\n",
        "        sales_metrics['sales_velocity'] = (\n",
        "            sales_metrics['total_quantity_sold'] / sales_metrics['days_on_market']\n",
        "        )\n",
        "        \n",
        "        # Merge with products\n",
        "        self.products_enhanced = self.products_enhanced.merge(\n",
        "            sales_metrics, on='product_id', how='left'\n",
        "        )\n",
        "        \n",
        "        # Fill NaN values\n",
        "        self.products_enhanced['sales_velocity'].fillna(0, inplace=True)\n",
        "        self.products_enhanced['days_since_last_sale'].fillna(999, inplace=True)\n",
        "        \n",
        "        # Calculate dead stock risk\n",
        "        self.products_enhanced['is_dead_stock_risk'] = self.products_enhanced.apply(\n",
        "            calculate_dead_stock_risk, axis=1\n",
        "        )\n",
        "        \n",
        "    def get_dead_stock_products(self, threshold_days=30):\n",
        "        \"\"\"Get products at risk of becoming dead stock\"\"\"\n",
        "        if self.products_enhanced is None:\n",
        "            self.enhance_product_features()\n",
        "            \n",
        "        at_risk = self.products_enhanced[\n",
        "            (self.products_enhanced['is_dead_stock_risk'] == 1) |\n",
        "            (self.products_enhanced['days_until_expiry'] <= threshold_days)\n",
        "        ].sort_values('days_until_expiry')\n",
        "        \n",
        "        return at_risk[['product_id', 'name', 'category', 'days_until_expiry',\n",
        "                       'sales_velocity', 'total_quantity_sold', 'current_discount_percent']]\n",
        "    \n",
        "    def generate_waste_reduction_recommendations(self, top_n_per_user=3):\n",
        "        \"\"\"\n",
        "        Generate recommendations for all users focusing on products at risk\n",
        "        \"\"\"\n",
        "        if self.products_enhanced is None:\n",
        "            self.enhance_product_features()\n",
        "        \n",
        "        # Get products at risk\n",
        "        at_risk_products = self.products_enhanced[\n",
        "            self.products_enhanced['is_dead_stock_risk'] == 1\n",
        "        ]\n",
        "        \n",
        "        all_recommendations = []\n",
        "        \n",
        "        for _, user in self.users_df.iterrows():\n",
        "            user_recs = get_user_recommendations(\n",
        "                user['user_id'], \n",
        "                at_risk_products, \n",
        "                self.users_df,\n",
        "                top_n=top_n_per_user,\n",
        "                focus_on_expiring=True\n",
        "            )\n",
        "            \n",
        "            if not user_recs.empty:\n",
        "                user_recs['user_id'] = user['user_id']\n",
        "                all_recommendations.append(user_recs)\n",
        "        \n",
        "        if all_recommendations:\n",
        "            return pd.concat(all_recommendations, ignore_index=True)\n",
        "        else:\n",
        "            return pd.DataFrame()\n",
        "    \n",
        "    def calculate_potential_waste_reduction(self):\n",
        "        \"\"\"\n",
        "        Calculate metrics showing potential waste reduction\n",
        "        \"\"\"\n",
        "        if self.products_enhanced is None:\n",
        "            self.enhance_product_features()\n",
        "            \n",
        "        at_risk_products = self.products_enhanced[\n",
        "            self.products_enhanced['is_dead_stock_risk'] == 1\n",
        "        ]\n",
        "        \n",
        "        metrics = {\n",
        "            'total_products': len(self.products_enhanced),\n",
        "            'products_at_risk': len(at_risk_products),\n",
        "            'percentage_at_risk': len(at_risk_products) / len(self.products_enhanced) * 100,\n",
        "            'products_expiring_7_days': len(\n",
        "                self.products_enhanced[self.products_enhanced['days_until_expiry'] <= 7]\n",
        "            ),\n",
        "            'products_expiring_30_days': len(\n",
        "                self.products_enhanced[self.products_enhanced['days_until_expiry'] <= 30]\n",
        "            ),\n",
        "            'avg_days_until_expiry_at_risk': at_risk_products['days_until_expiry'].mean()\n",
        "        }\n",
        "        \n",
        "        return metrics\n",
        "\n",
        "# Initialize the system\n",
        "waste_reduction_system = WasteReductionSystem(\n",
        "    users_df=users_df,\n",
        "    products_df=products_df,\n",
        "    transactions_df=transactions_df,\n",
        "    model=rf_model,\n",
        "    scaler=scaler\n",
        ")\n",
        "\n",
        "# Enhance product features\n",
        "waste_reduction_system.enhance_product_features()\n",
        "\n",
        "print(\"Waste Reduction System initialized successfully!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "### Step 4.2: Demonstrate the System\n",
        "\n",
        "Let's see the waste reduction system in action by:\n",
        "1. Identifying products at risk\n",
        "2. Generating targeted recommendations\n",
        "3. Calculating potential impact\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 1. Get waste reduction metrics\n",
        "metrics = waste_reduction_system.calculate_potential_waste_reduction()\n",
        "print(\"WASTE REDUCTION METRICS:\")\n",
        "print(\"=\"*50)\n",
        "for key, value in metrics.items():\n",
        "    if isinstance(value, float):\n",
        "        print(f\"{key}: {value:.2f}\")\n",
        "    else:\n",
        "        print(f\"{key}: {value}\")\n",
        "\n",
        "# 2. Get products at risk of becoming dead stock\n",
        "print(\"\\n\\nPRODUCTS AT RISK OF BECOMING DEAD STOCK:\")\n",
        "print(\"=\"*50)\n",
        "dead_stock_products = waste_reduction_system.get_dead_stock_products()\n",
        "print(f\"Found {len(dead_stock_products)} products at risk\")\n",
        "print(\"\\nTop 10 most urgent products:\")\n",
        "print(dead_stock_products.head(10))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 3. Generate recommendations to reduce waste\n",
        "print(\"\\n\\nGENERATING WASTE REDUCTION RECOMMENDATIONS:\")\n",
        "print(\"=\"*50)\n",
        "recommendations = waste_reduction_system.generate_waste_reduction_recommendations(top_n_per_user=2)\n",
        "\n",
        "if not recommendations.empty:\n",
        "    print(f\"Generated {len(recommendations)} total recommendations\")\n",
        "    print(f\"Covering {recommendations['user_id'].nunique()} users\")\n",
        "    print(f\"Targeting {recommendations['product_id'].nunique()} at-risk products\")\n",
        "    \n",
        "    # Show sample recommendations\n",
        "    print(\"\\n\\nSAMPLE RECOMMENDATIONS:\")\n",
        "    print(\"=\"*50)\n",
        "    sample_users = recommendations['user_id'].unique()[:3]\n",
        "    \n",
        "    for user_id in sample_users:\n",
        "        user_recs = recommendations[recommendations['user_id'] == user_id]\n",
        "        user_info = users_df[users_df['user_id'] == user_id].iloc[0]\n",
        "        \n",
        "        print(f\"\\nUser {user_id}:\")\n",
        "        print(f\"  Diet: {user_info['diet_type']}, Prefers Discount: {user_info['prefers_discount']}\")\n",
        "        print(\"  Recommendations:\")\n",
        "        for _, rec in user_recs.iterrows():\n",
        "            print(f\"    - {rec['product_name']} ({rec['category']})\")\n",
        "            print(f\"      Days until expiry: {rec['days_until_expiry']}, Score: {rec['compatibility_score']:.1f}\")\n",
        "else:\n",
        "    print(\"No recommendations generated (possibly no at-risk products match user preferences)\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "### Step 4.3: Visualize System Performance\n",
        "\n",
        "Let's create visualizations to better understand the system's impact and performance.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create visualizations\n",
        "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
        "\n",
        "# 1. Distribution of days until expiry\n",
        "ax1 = axes[0, 0]\n",
        "products_enhanced['days_until_expiry'].hist(bins=30, ax=ax1, color='skyblue', edgecolor='black')\n",
        "ax1.axvline(x=30, color='red', linestyle='--', label='30-day threshold')\n",
        "ax1.set_xlabel('Days Until Expiry')\n",
        "ax1.set_ylabel('Number of Products')\n",
        "ax1.set_title('Distribution of Product Expiry Times')\n",
        "ax1.legend()\n",
        "\n",
        "# 2. Dead stock risk by category\n",
        "ax2 = axes[0, 1]\n",
        "risk_by_category = products_enhanced.groupby('category')['is_dead_stock_risk'].mean() * 100\n",
        "risk_by_category.plot(kind='bar', ax=ax2, color='coral')\n",
        "ax2.set_xlabel('Category')\n",
        "ax2.set_ylabel('% Products at Risk')\n",
        "ax2.set_title('Dead Stock Risk by Product Category')\n",
        "ax2.tick_params(axis='x', rotation=45)\n",
        "\n",
        "# 3. Sales velocity distribution\n",
        "ax3 = axes[1, 0]\n",
        "products_enhanced[products_enhanced['sales_velocity'] > 0]['sales_velocity'].hist(\n",
        "    bins=30, ax=ax3, color='lightgreen', edgecolor='black'\n",
        ")\n",
        "ax3.set_xlabel('Sales Velocity (units/day)')\n",
        "ax3.set_ylabel('Number of Products')\n",
        "ax3.set_title('Distribution of Sales Velocity (excluding zero sales)')\n",
        "\n",
        "# 4. Recommendation coverage\n",
        "ax4 = axes[1, 1]\n",
        "if not recommendations.empty:\n",
        "    coverage_data = pd.DataFrame({\n",
        "        'Total Products': [len(products_enhanced)],\n",
        "        'At Risk': [len(products_enhanced[products_enhanced['is_dead_stock_risk'] == 1])],\n",
        "        'Recommended': [recommendations['product_id'].nunique()]\n",
        "    })\n",
        "    coverage_data.plot(kind='bar', ax=ax4, color=['blue', 'orange', 'green'])\n",
        "    ax4.set_xlabel('Category')\n",
        "    ax4.set_ylabel('Number of Products')\n",
        "    ax4.set_title('Recommendation System Coverage')\n",
        "    ax4.tick_params(axis='x', rotation=0)\n",
        "else:\n",
        "    ax4.text(0.5, 0.5, 'No recommendations generated', \n",
        "             horizontalalignment='center', verticalalignment='center')\n",
        "    ax4.set_title('Recommendation System Coverage')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## Summary and Usage Guide\n",
        "\n",
        "### System Overview\n",
        "\n",
        "This Waste Reduction System combines two powerful components:\n",
        "\n",
        "1. **Dead Stock Prediction Model**\n",
        "   - Uses Random Forest to predict products at risk of expiring unsold\n",
        "   - Key features: days until expiry, sales velocity, days since last sale\n",
        "   - Helps identify products needing immediate attention\n",
        "\n",
        "2. **Smart Recommendation Engine**\n",
        "   - Matches at-risk products with compatible users\n",
        "   - Considers: dietary restrictions, allergies, price preferences, category preferences\n",
        "   - Prioritizes products closest to expiry\n",
        "\n",
        "### How to Use the System\n",
        "\n",
        "```python\n",
        "# 1. Initialize the system\n",
        "system = WasteReductionSystem(users_df, products_df, transactions_df)\n",
        "\n",
        "# 2. Get products at risk\n",
        "at_risk = system.get_dead_stock_products(threshold_days=30)\n",
        "\n",
        "# 3. Generate recommendations\n",
        "recommendations = system.generate_waste_reduction_recommendations(top_n_per_user=5)\n",
        "\n",
        "# 4. Get metrics\n",
        "metrics = system.calculate_potential_waste_reduction()\n",
        "```\n",
        "\n",
        "### Business Impact\n",
        "\n",
        "- **Reduced Waste**: Proactively identifies products before they expire\n",
        "- **Increased Revenue**: Converts potential losses into sales through targeted recommendations\n",
        "- **Customer Satisfaction**: Users receive personalized deals on products they can actually use\n",
        "- **Sustainability**: Contributes to reducing food waste and environmental impact\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "### Step 2.3: Build Dead Stock Prediction Model\n",
        "\n",
        "We'll use a Random Forest Classifier to predict dead stock risk based on product features. This model will help us proactively identify products that need intervention.\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
